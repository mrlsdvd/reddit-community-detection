{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from graph_model import load_topic_frequencies, keep_top_n_topics, create_user_user_graph, connect_on_IOU\n",
    "from analyze_graphs import configuration_model, modularity_communities, top_down_communities, extract_topics_from_community\n",
    "from analyze_graphs import community_topic_evolution, sample_topics, compute_betweenness_graph, compute_community_betweenness, determine_prototype\n",
    "from utils import plot_graph, get_literal_topics, create_topic_map, load_graph, save_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "# Long\n",
    "# user_topic_graph_path = \"../data/processed/author_topic_long.txt\"\n",
    "# user_topic_graph_reduced_path = \"../data/processed/author_topic_reduced_long.txt\"\n",
    "# topic_freqs_path = \"../data/processed/topic_freq_long.txt\"\n",
    "# user_user_graph_path = \"../data/processed/user_user_long.txt\"\n",
    "# topics_path = \"../data/processed/topics_long.txt\"\n",
    "\n",
    "# Small\n",
    "# user_topic_graph_path = \"../data/processed/author_topic_small.txt\"\n",
    "# user_topic_graph_reduced_path = \"../data/processed/author_topic_reduced_small.txt\"\n",
    "# topic_freqs_path = \"../data/processed/topic_freq_small.txt\"\n",
    "# user_user_graph_path = \"../data/processed/user_user_small.txt\"\n",
    "# topics_path = \"../data/processed/topics_small.txt\"\n",
    "\n",
    "# Medium\n",
    "user_topic_graph_path = \"../data/processed/author_topic_medium.txt\"\n",
    "user_topic_graph_reduced_path = \"../data/processed/author_topic_reduced_medium.txt\"\n",
    "topic_freqs_path = \"../data/processed/topic_freq_medium.txt\"\n",
    "user_user_graph_path = \"../data/processed/user_user_medium.txt\"\n",
    "topics_path = \"../data/processed/topics_medium.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create user-topic and user-user graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 74902\n",
      "Number of edges: 1208000\n"
     ]
    }
   ],
   "source": [
    "# Create user-topic graph\n",
    "user_topic_graph = load_graph(user_topic_graph_path)\n",
    "topic_freqs = load_topic_frequencies(topic_freqs_path)\n",
    "# Keep only top n topics in graph\n",
    "user_topic_graph = keep_top_n_topics(user_topic_graph, topic_freqs, n=200)\n",
    "save_graph(user_topic_graph, user_topic_graph_reduced_path)\n",
    "\n",
    "# Load user-topic graph\n",
    "# user_topic_graph = load_graph(user_topic_graph_reduced_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1000\n",
      "Number of edges: 250268\n"
     ]
    }
   ],
   "source": [
    "# Create use-user graph\n",
    "user_user_graph = create_user_user_graph(user_topic_graph, connect_on_IOU, out_filename=user_user_graph_path)\n",
    "# user_user_graph = load_graph(user_user_graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw crude graph\n",
    "plot_graph(user_user_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration model graph\n",
    "config_user_user_graph = configuration_model(user_user_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw crude config graph\n",
    "plot_graph(config_user_user_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect communities in user-user graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 communities\n",
      "Community sizes: [455, 373, 3]\n"
     ]
    }
   ],
   "source": [
    "# Compute modularity-maximizing communities for user-user graph\n",
    "mod_communities = modularity_communities(user_user_graph)\n",
    "# Remove communities smaller than n\n",
    "community_size_thresh = 2\n",
    "mod_communities = list(filter(lambda c: len(c) > community_size_thresh, mod_communities))\n",
    "num_communities = len(mod_communities)\n",
    "print(\"{} communities\".format(num_communities))\n",
    "print(\"Community sizes: {}\".format(list(map(lambda c: len(c), mod_communities))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot communities\n",
    "plot_graph(user_user_graph, mod_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute modularity-maximizing communities for config graph\n",
    "config_mod_communities = modularity_communities(config_user_user_graph)\n",
    "config_num_communities = len(config_mod_communities)\n",
    "print(\"{} communities\".format(config_num_communities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Modularity Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per community: 166\n",
      "{1, 2, 8, 9, 11, 12, 17, 25, 27, 29, 33, 37, 39, 40, 41, 46, 48, 49, 50, 54, 56, 66, 67, 72, 73, 76, 77, 80, 84, 93, 94, 95, 97, 100, 101, 105, 107, 108, 110, 115, 117, 119, 123, 125, 130, 131, 135, 136, 139, 141, 147, 151, 159, 160, 161, 164, 171, 172, 176, 177, 178, 180, 183, 186, 192, 208, 209, 211, 217, 218, 220, 221, 225, 226, 228, 231, 234, 236, 237, 241, 248, 250, 252, 255, 258, 260, 263, 265, 273, 275, 278, 279, 282, 287, 289, 294, 296, 297, 298, 301, 302, 303, 306, 307, 310, 312, 314, 315, 318, 319, 324, 325, 326, 329, 331, 337, 338, 342, 345, 346, 347, 350, 351, 355, 356, 359, 361, 365, 366, 367, 368, 373, 374, 376, 380, 381, 383, 384, 386, 389, 391, 395, 398, 400, 409, 411, 417, 421, 422, 433, 434, 437, 440, 441, 443, 445, 450, 452, 453, 457, 458, 473, 474, 475, 476, 477, 479, 483, 489, 490, 492, 496, 497, 500, 501, 503, 507, 509, 515, 517, 518, 522, 524, 529, 532, 535, 538, 543, 546, 548, 549, 550, 551, 558, 564, 569, 572, 575, 578, 581, 585, 586, 587, 588, 591, 596, 598, 602, 603, 604, 605, 608, 611, 613, 617, 618, 621, 627, 628, 633, 636, 644, 651, 653, 654, 655, 661, 664, 665, 675, 676, 679, 684, 685, 686, 687, 688, 692, 701, 704, 705, 707, 711, 712, 715, 718, 725, 728, 731, 732, 733, 735, 737, 742, 746, 750, 751, 755, 757, 758, 760, 761, 765, 766, 768, 775, 779, 781, 787, 791, 794, 797, 803, 804, 809, 812, 813, 814, 816, 819, 820, 825, 828, 831, 835, 848, 851, 855, 858, 865, 871, 875, 877, 878, 879, 881, 889, 892, 896, 899, 900, 901, 902, 906, 908, 909, 913, 915, 916, 926, 928, 929, 932, 936, 941, 951, 954, 955, 957, 961, 966, 967, 968, 969, 970, 971, 975, 976, 978, 980, 985, 988, 989, 992, 994, 997, 998}\n"
     ]
    }
   ],
   "source": [
    "# Measure betweenness of each community\n",
    "graph_betweenness = compute_betweenness_graph(user_user_graph, mod_communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create topic map\n",
    "topic_map = create_topic_map(topics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community Betweenness: 13.422016009902322\n",
      "Prototype has 10 topics: [\"('right', '+')\", \"('income', '+')\", \"('difference', '+')\", \"('tax', '+')\", \"('time', '+')\", \"('everyone', '+')\", \"('business', '+')\", \"('money', '+')\", \"('fact', '+')\", \"('wage', '+')\"]\n",
      "Top 10 topics: [\"('amendment', '-')\", \"('amendment', '+')\", \"('decision', '+')\", \"('speech', '+')\", \"('reddit', '+')\", \"('candidate', '+')\", \"('bush', '+')\", \"('wealth', '+')\", \"('murder', '-')\", \"('plan', '-')\", \"('voting', '+')\", \"('healthcare', '+')\", \"('labor', '+')\", \"('please', '+')\", \"('process', '-')\", \"('claim', '-')\", \"('process', '+')\", \"('population', '-')\", \"('increase', '+')\", \"('constitution', '+')\"]\n",
      "Community Betweenness: 23.10831996436017\n",
      "Prototype has 10 topics: [\"('country', '+')\", \"('look', '+')\", \"('problem', '-')\", \"('home', '-')\", \"('world', '-')\", \"('use', '-')\", \"('look', '-')\", \"('office', '-')\", \"('reason', '+')\", \"('today', '+')\"]\n",
      "Top 10 topics: [\"('thank', '+')\", \"('nobody', '-')\", \"('voter', '-')\", \"('please', '-')\", \"('fraud', '-')\", \"('speech', '+')\", \"('feel', '+')\", \"('amendment', '-')\", \"('reddit', '+')\", \"('gun', '+')\", \"('healthcare', '+')\", \"('wealth', '+')\", \"('gop', '-')\", \"('amendment', '+')\", \"('bush', '+')\", \"('murder', '-')\", \"('story', '+')\", \"('spending', '+')\", \"('story', '-')\", \"('population', '-')\"]\n",
      "Community Betweenness: 42.19312292936659\n",
      "Prototype has 10 topics: [\"('opinion', '+')\", \"('hand', '+')\", \"('position', '+')\", \"('market', '+')\", \"('control', '-')\", \"('argument', '-')\", \"('family', '-')\", \"('police', '-')\", \"('gun', '-')\", \"('something', '-')\"]\n",
      "Top 10 topics: [\"('history', '+')\", \"('economy', '-')\", \"('fact', '-')\", \"('news', '+')\", \"('cost', '+')\", \"('please', '+')\", \"('power', '+')\", \"('hell', '-')\", \"('story', '+')\", \"('economy', '+')\", \"('violence', '-')\", \"('everything', '-')\", \"('show', '-')\", \"('order', '+')\", \"('state', '-')\", \"('anyone', '-')\", \"('country', '+')\", \"('situation', '+')\", \"('world', '+')\", \"('gun', '+')\"]\n"
     ]
    }
   ],
   "source": [
    "for community in mod_communities:\n",
    "    # Compute betweenness of community\n",
    "    community_betweenness = compute_community_betweenness(graph_betweenness, community)\n",
    "    print(\"Community Betweenness: {}\".format(community_betweenness))\n",
    "    # Extract top topics\n",
    "    topic_scores = extract_topics_from_community(user_topic_graph, community)\n",
    "    top_topic_nodes = sample_topics(topic_scores, n=20)\n",
    "    top_topics = get_literal_topics(top_topic_nodes, topic_map)\n",
    "    # Find prototype and get its topics\n",
    "    prototype = determine_prototype(user_user_graph, community)\n",
    "    if prototype is not None:\n",
    "        prototype_topics = user_topic_graph.neighbors(prototype)\n",
    "        prototype_literals = get_literal_topics(prototype_topics, topic_map)\n",
    "    n = 10\n",
    "    print(\"Prototype has {} topics: {}\".format(n, prototype_literals[:n]))\n",
    "    print(\"Top 10 topics: {}\".format(top_topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze communities over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num levels: 0\n"
     ]
    }
   ],
   "source": [
    "# Compute community levels\n",
    "community_levels = top_down_communities(user_user_graph, num_communities)\n",
    "print(\"Num levels: {}\".format(len(community_levels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get community level evolution\n",
    "evolution = community_topic_evolution(community_levels, user_topic_graph, sample_n=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report evolution\n",
    "for i, level in enumerate(evolution):\n",
    "    print(\"Level {}:\".format(i+1))\n",
    "    for j, community_topic_scores in enumerate(level):\n",
    "        community_topics = sample_topics(community_topic_scores, n=10) \n",
    "        community_topics = get_literal_topics(community_topics, topic_map)\n",
    "        print(\"\\tTopics for community {}: {}\".format(j+1, community_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
